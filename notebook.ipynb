{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Scenification - Tag Analysis Notebook\n",
    "\n",
    "This notebook allows you to run the tag analysis script and explore the resulting data.\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project analyzes scene usage in English novels circa 1800 by processing custom-tagged HTML files to extract metrics on narrative techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run Tag Analysis\n",
    "\n",
    "First, let's run the `count_tags.py` script which will:\n",
    "- Process HTML files in `data/input/`\n",
    "- Generate CSV files in `data/counts/`\n",
    "- Create a summary Excel file at `data/tag_counts_summary.xlsx`\n",
    "- Generate Markdown summaries in `data/SUMMARY.md` and `data/SAMPLES.md`\n",
    "\n",
    "Run the cell below to execute the script:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the library package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPORTANT: After installing make sure to RESTART the notebook kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the external tag analysis script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python count_tags.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Libraries\n",
    "\n",
    "Now let's import the necessary libraries for data analysis and visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML, Markdown\n",
    "\n",
    "# Configure visualization style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Explore Input and Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List input HTML files\n",
    "input_files = sorted(glob.glob('data/input/*.html'))\n",
    "print(f\"Found {len(input_files)} HTML files in data/input/\")\n",
    "\n",
    "# Display the first few files and their sizes\n",
    "print(\"\\nInput HTML files:\")\n",
    "for file in input_files[:5]:\n",
    "    size_kb = os.path.getsize(file) / 1024\n",
    "    print(f\"- {os.path.basename(file)} ({size_kb:.1f} KB)\")\n",
    "    \n",
    "if len(input_files) > 5:\n",
    "    print(f\"...and {len(input_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List output CSV files\n",
    "output_files = sorted(glob.glob('data/counts/*.csv'))\n",
    "print(f\"Found {len(output_files)} CSV files in data/counts/\")\n",
    "\n",
    "# Display the first few files\n",
    "print(\"\\nOutput CSV files:\")\n",
    "for file in output_files[:5]:\n",
    "    print(f\"- {os.path.basename(file)}\")\n",
    "    \n",
    "if len(output_files) > 5:\n",
    "    print(f\"...and {len(output_files) - 5} more files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyze an Individual Text\n",
    "\n",
    "Let's create a function to analyze tag patterns in a specific text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(text_name=None):\n",
    "    \"\"\"Analyze tag distributions in a specific text\n",
    "    \n",
    "    Args:\n",
    "        text_name: Part of the filename to match. If None, will analyze the first file.\n",
    "    \"\"\"\n",
    "    # Get all CSV files\n",
    "    csv_files = glob.glob('data/counts/*.csv')\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found. Run the tag analysis first.\")\n",
    "        return None\n",
    "    \n",
    "    # If no text specified, use the first one\n",
    "    if text_name is None:\n",
    "        csv_file = csv_files[0]\n",
    "    else:\n",
    "        # Find matching files\n",
    "        matches = [f for f in csv_files if text_name in f]\n",
    "        if not matches:\n",
    "            print(f\"No files found matching '{text_name}'\")\n",
    "            return None\n",
    "        csv_file = matches[0]\n",
    "    \n",
    "    print(f\"Analyzing: {os.path.basename(csv_file)}\")\n",
    "    \n",
    "    # Load the CSV\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Get document totals\n",
    "    totals = df[df['tag'] == 'totaldoctagswords'].iloc[0]\n",
    "    total_tags = totals['tag_count']\n",
    "    total_words = totals['word_count']\n",
    "    \n",
    "    print(f\"Total tags: {total_tags}\")\n",
    "    print(f\"Total words: {total_words}\")\n",
    "    \n",
    "    # Remove totals row\n",
    "    df = df[df['tag'] != 'totaldoctagswords']\n",
    "    \n",
    "    # Show top tags by frequency\n",
    "    freq_df = df.sort_values('tag_count', ascending=False).head(15)\n",
    "    print(\"\\nTop 15 most frequent tags:\")\n",
    "    display(freq_df[['tag', 'tag_count', 'word_count']])\n",
    "    \n",
    "    # Visualize top tags by frequency\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x='tag', y='tag_count', data=freq_df)\n",
    "    plt.title(f'Top Tags by Frequency in {os.path.basename(csv_file)}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize top tags by word count\n",
    "    word_df = df.sort_values('word_count', ascending=False).head(15)\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x='tag', y='word_count', data=word_df)\n",
    "    plt.title(f'Top Tags by Word Count in {os.path.basename(csv_file)}')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the first text (if available)\n",
    "output_files = glob.glob('data/counts/*.csv')\n",
    "if output_files:\n",
    "    text_df = analyze_text()\n",
    "else:\n",
    "    print(\"No output files found. Please run the tag analysis script first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Nested Tag Combinations\n",
    "\n",
    "Let's examine compound tags (those with an underscore, indicating nesting) across the corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_compound_tags():\n",
    "    \"\"\"Analyze nested tag combinations across all texts\"\"\"\n",
    "    # Load all CSV files\n",
    "    csv_files = glob.glob('data/counts/*.csv')\n",
    "    if not csv_files:\n",
    "        print(\"No CSV files found. Run the tag analysis first.\")\n",
    "        return None\n",
    "    \n",
    "    # Combine data from all files\n",
    "    all_data = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        text_name = os.path.basename(csv_file).replace('.csv', '')\n",
    "        df['text'] = text_name\n",
    "        all_data.append(df)\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    \n",
    "    # Filter for compound tags (containing underscore)\n",
    "    compound_tags = combined_df[combined_df['tag'].str.contains('_')]\n",
    "    \n",
    "    # Sum counts across all texts\n",
    "    tag_totals = compound_tags.groupby('tag').agg({\n",
    "        'tag_count': 'sum',\n",
    "        'word_count': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Get top compounds by frequency\n",
    "    top_by_freq = tag_totals.sort_values('tag_count', ascending=False).head(15)\n",
    "    print(\"Top nested tag combinations by frequency:\")\n",
    "    display(top_by_freq)\n",
    "    \n",
    "    # Visualize top compounds\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x='tag', y='tag_count', data=top_by_freq)\n",
    "    plt.title('Top Nested Tag Combinations by Frequency')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Get top compounds by word count\n",
    "    top_by_words = tag_totals.sort_values('word_count', ascending=False).head(15)\n",
    "    print(\"\\nTop nested tag combinations by word count:\")\n",
    "    display(top_by_words)\n",
    "    \n",
    "    # Visualize top compounds by word count\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x='tag', y='word_count', data=top_by_words)\n",
    "    plt.title('Top Nested Tag Combinations by Word Count')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return compound_tags\n",
    "\n",
    "# Run the analysis\n",
    "compound_data = analyze_compound_tags()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
